---
title: Introduction
description: The simplest, fastest repository for training and finetuning medium-sized GPT language models
---

# Welcome to nanoGPT

nanoGPT is a minimalist yet powerful implementation for training and finetuning medium-sized GPT language models. Created by Andrej Karpathy, it prioritizes simplicity, readability, and performance over educational abstractions.

<Note>
  **Update Nov 2025**: nanoGPT has a new and improved cousin called [nanochat](https://github.com/karpathy/nanochat). For new projects, you may want to consider nanochat instead. However, nanoGPT remains an excellent learning resource and a solid foundation for GPT training.
</Note>

## What is nanoGPT?

nanoGPT is a rewrite of [minGPT](https://github.com/karpathy/minGPT) that focuses on practical training capabilities. The entire codebase consists of:

- **~300 lines** for the training loop (`train.py`)
- **~300 lines** for the GPT model definition (`model.py`)
- Optional loading of GPT-2 weights from OpenAI

Despite its simplicity, nanoGPT can reproduce GPT-2 (124M parameters) on OpenWebText, running on a single 8xA100 40GB node in approximately 4 days of training.

## Key Features

<CardGroup cols={2}>
  <Card title="Simple & Readable" icon="code">
    Clean, hackable code that's easy to understand and modify. Perfect for learning and experimentation.
  </Card>
  
  <Card title="Production Ready" icon="rocket">
    Reproduces GPT-2 (124M) on OpenWebText with proper training infrastructure and optimizations.
  </Card>
  
  <Card title="Fast Training" icon="bolt">
    PyTorch 2.0 compile support cuts iteration time from ~250ms to ~135ms. Flash Attention for efficient GPU utilization.
  </Card>
  
  <Card title="Distributed Support" icon="server">
    Built-in DDP (Distributed Data Parallel) support for multi-GPU and multi-node training.
  </Card>
  
  <Card title="Flexible Configuration" icon="sliders">
    Python-based config files make it easy to customize training runs and model architectures.
  </Card>
  
  <Card title="Pretrained Models" icon="download">
    Load and finetune GPT-2 checkpoints (124M, 350M, 774M, 1558M) from OpenAI.
  </Card>
</CardGroup>

## Why Choose nanoGPT?

**For Researchers & Practitioners**: nanoGPT provides a clean slate for experimenting with GPT architectures. The simple codebase makes it easy to:
- Train custom models from scratch
- Finetune pretrained GPT-2 checkpoints on your own data
- Experiment with architectural modifications
- Prototype new training techniques

**For Learners**: Unlike educational implementations that abstract away details, nanoGPT shows you exactly what's happening:
- Transparent training loop with no hidden magic
- Clear model architecture in pure PyTorch
- Real-world optimizations and best practices
- Production-quality code you can learn from

## Quick Overview

### Model Architecture

nanoGPT implements the standard GPT architecture:
- Causal self-attention with multiple heads
- MLP blocks with GELU activation
- Layer normalization
- Residual connections
- Token and position embeddings

### Training Capabilities

<CardGroup cols={3}>
  <Card title="Character-Level" icon="font">
    Train on character-level data (e.g., Shakespeare) in minutes on a single GPU.
  </Card>
  
  <Card title="BPE Tokenization" icon="align-left">
    Use OpenAI's tiktoken for GPT-2 compatible BPE tokenization.
  </Card>
  
  <Card title="Finetuning" icon="wand-magic-sparkles">
    Start from pretrained GPT-2 checkpoints and adapt to your domain.
  </Card>
</CardGroup>

## Performance

On OpenWebText validation set:

| Model | Parameters | Train Loss | Val Loss | Hardware |
|-------|------------|------------|----------|----------|
| GPT-2 | 124M | 3.11 | 3.12 | 8xA100 40GB |
| GPT-2 Medium | 350M | 2.85 | 2.84 | 8xA100 40GB |
| GPT-2 Large | 774M | 2.66 | 2.67 | Multi-node |
| GPT-2 XL | 1558M | 2.56 | 2.54 | Multi-node |

<Tip>
  With PyTorch 2.0's `torch.compile()`, training speed improves significantly (2x faster iteration times) with just one line of code!
</Tip>

## Get Started

<CardGroup cols={2}>
  <Card title="Installation" icon="download" href="/installation">
    Install dependencies and set up your environment in minutes.
  </Card>
  
  <Card title="Quick Start" icon="play" href="/quickstart">
    Train your first GPT on Shakespeare in under 5 minutes.
  </Card>
  
  <Card title="Training Guide" icon="graduation-cap" href="/training/overview">
    Learn about training configurations and best practices.
  </Card>
  
  <Card title="API Reference" icon="book" href="/api/gpt">
    Explore the model architecture and training API.
  </Card>
</CardGroup>

## Community & Support

For questions, discussions, and support:

- **GitHub**: [karpathy/nanoGPT](https://github.com/karpathy/nanoGPT)
- **Discord**: Join the **#nanoGPT** channel
- **Learning**: Watch Andrej's [Zero To Hero series](https://karpathy.ai/zero-to-hero.html) and the [GPT video](https://www.youtube.com/watch?v=kCc8FmEb1nY)

<Warning>
  nanoGPT requires PyTorch 2.0 for optimal performance. On some platforms (e.g., Windows), you may need to disable `torch.compile()` by adding `--compile=False` to your training commands.
</Warning>

## What's Next?

Ready to dive in? Head over to the [Installation](/installation) guide to set up your environment, or jump straight to the [Quick Start](/quickstart) to train your first model!